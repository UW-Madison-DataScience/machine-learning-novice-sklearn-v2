<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Introduction to Machine Learning with Scikit-Learn: Unsupervised methods - Dimensionality reduction</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css"><script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png"><link rel="manifest" href="../favicons/incubator/site.webmanifest"><link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Beginner-friendly introduction to machine learning in Python using scikit-learn." src="../assets/images/incubator-logo.svg"><span class="badge text-bg-info">
          <abbr title="This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-circle" style="border-radius: 5px"></i>
              Beta
            </a>
            <span class="visually-hidden">This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='../06-dimensionality-reduction.html';">Learner View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Beginner-friendly introduction to machine learning in Python using scikit-learn." src="../assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Introduction to Machine Learning with Scikit-Learn
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Introduction to Machine Learning with Scikit-Learn
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Introduction to Machine Learning with Scikit-Learn
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 75%" class="percentage">
    75%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 75%" aria-valuenow="75" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../06-dimensionality-reduction.html">Learner View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-regression.html">2. Supervised methods - Regression</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-classification.html">3. Supervised methods - Classification</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-ensemble-methods.html">4. Ensemble methods</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-clustering.html">5. Unsupervised methods - Clustering</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        6. Unsupervised methods - Dimensionality reduction
        </span>
      
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-neural-networks.html">7. Neural Networks</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08-ethics.html">8. Ethics and the Implications of Machine Learning</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09-learn-more.html">9. Find out more</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr><li><a class="dropdown-item" href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-clustering.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-neural-networks.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-clustering.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Unsupervised methods
        </a>
        <a class="chapter-link float-end" href="../instructor/07-neural-networks.html" rel="next">
          Next: Neural Networks...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Unsupervised methods - Dimensionality reduction</h1>
        <p>Last updated on 2025-11-10 |

        <a href="https://github.com/UW-Madison-DataScience/machine-learning-novice-sklearn-v2/edit/main/episodes/06-dimensionality-reduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 60 minutes</p>

        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>How do we apply machine learning techniques to data with higher
dimensions?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Recall that most data is inherently multidimensional.</li>
<li>Understand that reducing the number of dimensions can simplify
modelling and allow classifications to be performed.</li>
<li>Apply Principle Component Analysis (PCA) and t-distributed
Stochastic Neighbor Embedding (t-SNE) to reduce the dimensions of
data.</li>
<li>Evaluate the relative peformance of PCA and t-SNE in reducing data
dimensionality.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="dimensionality-reduction">Dimensionality reduction<a class="anchor" aria-label="anchor" href="#dimensionality-reduction"></a></h1>
<p>As seen in the last episode, general clustering algorithms work well
with low-dimensional data. In this episode we see how higher-dimensional
data, such as images of handwritten text or numbers, can be processed
with dimensionality reduction techniques to make the datasets more
accessible for other modelling techniques. The dataset we will be using
is the Scikit-Learn subset of the Modified National Institute of
Standards and Technology (MNIST) dataset.</p>
<figure><img src="../fig/MnistExamples.png" alt="MNIST example illustrating all the classes in the dataset" class="figure mx-auto d-block"><div class="figcaption">MNIST example illustrating all the classes in
the dataset</div>
</figure><p>The MNIST dataset contains 70,000 images of handwritten numbers, and
are labelled from 0-9 with the number that each image contains. Each
image is a greyscale and 28x28 pixels in size for a total of 784 pixels
per image. Each pixel can take a value between 0-255 (8bits). When
dealing with a series of images in machine learning we consider each
pixel to be a feature that varies according to each of the sample
images. Our previous penguin dataset only had no more than 7 features to
train with, however even a small 28x28 MNIST image has as much as 784
features (pixels) to work with.</p>
<figure><img src="../fig/mnist_30000-letter.png" alt="MNIST example of a single image" class="figure mx-auto d-block"><div class="figcaption">MNIST example of a single image</div>
</figure><p>To make this episode a bit less computationally intensive, the
Scikit-Learn example that we will work with is a smaller sample of 1797
images. Each image is 8x8 in size for a total of 64 pixels per image,
resulting in 64 features for us to work with. The pixels can take a
value between 0-15 (4bits). Let’s retrieve and inspect the Scikit-Learn
dataset with the following code:</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># Let's define these here to avoid repetitive code</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="kw">def</span> plots_labels(data, labels):</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co">    Visualizes data points with associated labels in a 2D scatter plot.</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">    data (ndarray): A 2D NumPy array with shape (n_samples, 2), representing the data points.</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">    labels (ndarray or list): A 1D array or list of labels corresponding to the data points.</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co">    None: Displays the scatter plot with labels as colors.</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    <span class="co"># Extract the x and y coordinates from the data</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>    tx <span class="op">=</span> data[:, <span class="dv">0</span>]</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>    ty <span class="op">=</span> data[:, <span class="dv">1</span>]</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>    </span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>    <span class="co"># Create a figure with a specified size</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(<span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>    </span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>    <span class="co"># Scatter plot the data points, coloring them by their labels</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>    plt.scatter(tx, ty, edgecolor<span class="op">=</span><span class="st">'k'</span>, c<span class="op">=</span>labels)</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>    </span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>    <span class="co"># Display the plot</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a><span class="kw">def</span> plot_clusters(data, clusters, Kmean):</span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="co">    Visualizes clustered data points with centroids marked.</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a><span class="co">    data (ndarray): A 2D NumPy array with shape (n_samples, 2), representing the data points.</span></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a><span class="co">    clusters (ndarray or list): A 1D array or list of cluster assignments for each data point.</span></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="co">    Kmean (KMeans object): The fitted KMeans object containing cluster centers.</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a><span class="co">    None: Displays the scatter plot with clusters as colors and centroids marked with red crosses.</span></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a>    <span class="co"># Extract the x and y coordinates from the data</span></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a>    tx <span class="op">=</span> data[:, <span class="dv">0</span>]</span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a>    ty <span class="op">=</span> data[:, <span class="dv">1</span>]</span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a>    </span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a>    <span class="co"># Create a figure with a specified size</span></span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(<span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb1-48"><a href="#cb1-48" tabindex="-1"></a>    </span>
<span id="cb1-49"><a href="#cb1-49" tabindex="-1"></a>    <span class="co"># Scatter plot the data points, coloring them by their cluster assignment</span></span>
<span id="cb1-50"><a href="#cb1-50" tabindex="-1"></a>    <span class="co"># plt.scatter(tx, ty, s=5, linewidth=0, c=clusters)</span></span>
<span id="cb1-51"><a href="#cb1-51" tabindex="-1"></a>    plt.scatter(tx, ty, c<span class="op">=</span>clusters, cmap<span class="op">=</span><span class="st">"nipy_spectral"</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb1-52"><a href="#cb1-52" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" tabindex="-1"></a>    <span class="co"># Loop through cluster centers and mark them with a red 'x'</span></span>
<span id="cb1-54"><a href="#cb1-54" tabindex="-1"></a>    <span class="cf">for</span> cluster_x, cluster_y <span class="kw">in</span> Kmean.cluster_centers_:</span>
<span id="cb1-55"><a href="#cb1-55" tabindex="-1"></a>        plt.scatter(cluster_x, cluster_y, s<span class="op">=</span><span class="dv">100</span>, c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb1-56"><a href="#cb1-56" tabindex="-1"></a>    </span>
<span id="cb1-57"><a href="#cb1-57" tabindex="-1"></a>    <span class="co"># Display the plot</span></span>
<span id="cb1-58"><a href="#cb1-58" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-59"><a href="#cb1-59" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" tabindex="-1"></a><span class="kw">def</span> plot_clusters_labels(data, labels):</span>
<span id="cb1-61"><a href="#cb1-61" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-62"><a href="#cb1-62" tabindex="-1"></a><span class="co">    Visualizes data points with associated labels using a color map and displays a legend.</span></span>
<span id="cb1-63"><a href="#cb1-63" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb1-65"><a href="#cb1-65" tabindex="-1"></a><span class="co">    data (ndarray): A 2D NumPy array with shape (n_samples, 2), representing the data points.</span></span>
<span id="cb1-66"><a href="#cb1-66" tabindex="-1"></a><span class="co">    labels (ndarray or list): A 1D array or list of labels corresponding to the data points.</span></span>
<span id="cb1-67"><a href="#cb1-67" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb1-69"><a href="#cb1-69" tabindex="-1"></a><span class="co">    None: Displays the scatter plot with labels as colors and a color bar for the label legend.</span></span>
<span id="cb1-70"><a href="#cb1-70" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-71"><a href="#cb1-71" tabindex="-1"></a>    <span class="co"># Extract the x and y coordinates from the data</span></span>
<span id="cb1-72"><a href="#cb1-72" tabindex="-1"></a>    tx <span class="op">=</span> data[:, <span class="dv">0</span>]</span>
<span id="cb1-73"><a href="#cb1-73" tabindex="-1"></a>    ty <span class="op">=</span> data[:, <span class="dv">1</span>]</span>
<span id="cb1-74"><a href="#cb1-74" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" tabindex="-1"></a>    <span class="co"># Create a figure with a specified size</span></span>
<span id="cb1-76"><a href="#cb1-76" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(<span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">4</span>))</span>
<span id="cb1-77"><a href="#cb1-77" tabindex="-1"></a>    </span>
<span id="cb1-78"><a href="#cb1-78" tabindex="-1"></a>    <span class="co"># Scatter plot the data points, coloring them by their labels and using a colormap</span></span>
<span id="cb1-79"><a href="#cb1-79" tabindex="-1"></a>    plt.scatter(tx, ty, c<span class="op">=</span>labels, cmap<span class="op">=</span><span class="st">"nipy_spectral"</span>, </span>
<span id="cb1-80"><a href="#cb1-80" tabindex="-1"></a>                edgecolor<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span>labels)</span>
<span id="cb1-81"><a href="#cb1-81" tabindex="-1"></a>    </span>
<span id="cb1-82"><a href="#cb1-82" tabindex="-1"></a>    <span class="co"># Add a color bar to show the label legend</span></span>
<span id="cb1-83"><a href="#cb1-83" tabindex="-1"></a>    plt.colorbar(boundaries<span class="op">=</span>np.arange(<span class="dv">11</span>) <span class="op">-</span> <span class="fl">0.5</span>).set_ticks(np.arange(<span class="dv">10</span>))</span>
<span id="cb1-84"><a href="#cb1-84" tabindex="-1"></a>    </span>
<span id="cb1-85"><a href="#cb1-85" tabindex="-1"></a>    <span class="co"># Display the plot</span></span>
<span id="cb1-86"><a href="#cb1-86" tabindex="-1"></a>    plt.show()</span></code></pre>
</div>
<p>Next lets load in the digits dataset,</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># load in dataset as a Pandas Dataframe, return X and Y</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>features, labels <span class="op">=</span> datasets.load_digits(return_X_y<span class="op">=</span><span class="va">True</span>, as_frame<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="bu">print</span>(features.shape, labels.shape)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="bu">print</span>(labels)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>features.head()</span></code></pre>
</div>
<div class="section level2">
<h2 id="preview-data">Preview data<a class="anchor" aria-label="anchor" href="#preview-data"></a></h2>
<p>Each image is 8x8 pixels. We can revert the current “flattened” (aka
vectorized) form by using reshape. The -1 tells NumPy to infer the
appropriate number of rows automatically. NumPy does this by dividing
the total number of elements in the original 1D array (image_1D.size) by
8 (the specified number of columns).</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="bu">print</span>(features.iloc[<span class="dv">0</span>])</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>image_1D <span class="op">=</span> features.iloc[<span class="dv">0</span>]</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>image_2D <span class="op">=</span> np.array(image_1D).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">8</span>)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>plt.imshow(image_2D,cmap<span class="op">=</span><span class="st">"gray_r"</span>)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="our-goal-using-dimensionality-reduction-to-help-with-machine-learning">Our goal: using dimensionality-reduction to help with machine
learning<a class="anchor" aria-label="anchor" href="#our-goal-using-dimensionality-reduction-to-help-with-machine-learning"></a></h2>
<p>As humans we are pretty good at object and pattern recognition. We
can look at the images above, inspect the intensity and position pixels
relative to other pixels, and pretty quickly make an accurate guess at
what the image shows. As humans we spends much of our younger lives
learning these spatial relations, and so it stands to reason that
computers can also extract these relations. Let’s see if it is possible
to use unsupervised clustering techniques to pull out relations in our
MNIST dataset of number images.</p>
<div id="exercise-try-to-visually-inspect-the-dataset-and-features-for-correlations" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="exercise-try-to-visually-inspect-the-dataset-and-features-for-correlations" class="callout-inner">
<h3 class="callout-title">Exercise: Try to visually inspect the dataset
and features for correlations</h3>
<div class="callout-content">
<p>As we did for previous datasets, lets visually inspect relationships
between our features/pixels. Try and investigate the following pixels
for relations (written “row_column”): 0_4, 1_4, 2_4, and 3_4.</p>
<div class="section level2">
<h2 id="solution">Solution<a class="anchor" aria-label="anchor" href="#solution"></a></h2>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="bu">print</span>(features.iloc[<span class="dv">0</span>])</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>image_1D <span class="op">=</span> features.iloc[<span class="dv">0</span>]</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>image_2D <span class="op">=</span> np.array(image_1D).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">8</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>plt.imshow(image_2D,cmap<span class="op">=</span><span class="st">"gray_r"</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co"># these points are the pixels we will investigate</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co"># pixels 0,1,2,3 of row 4 of the image</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>plt.plot([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>],[<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>],<span class="st">"rx"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/results/mnist_pairplot_pixels.png" alt="SKLearn image with highlighted pixels" class="figure mx-auto d-block"><div class="figcaption">SKLearn image with highlighted pixels</div>
</figure><div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># make a temporary copy of data for plotting here only</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>seaborn_data <span class="op">=</span> features</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co"># add labels for pairplot color coding</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>seaborn_data[<span class="st">"labels"</span>] <span class="op">=</span> labels</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co"># make a short list of N features for plotting N*N figures</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="co"># 4**2 = 16 plots, whereas 64**2 is over 4000!</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>feature_subset <span class="op">=</span> []</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    feature_subset.append(<span class="st">"pixel_"</span><span class="op">+</span><span class="bu">str</span>(i)<span class="op">+</span><span class="st">"_4"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>sns.pairplot(seaborn_data, <span class="bu">vars</span><span class="op">=</span>feature_subset, hue<span class="op">=</span><span class="st">"labels"</span>, </span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>             palette<span class="op">=</span>sns.mpl_palette(<span class="st">"Spectral"</span>, n_colors<span class="op">=</span><span class="dv">10</span>))</span></code></pre>
</div>
<figure><img src="../fig/results/mnist_pairplot.png" alt="SKLearn image with highlighted pixels" class="figure mx-auto d-block"><div class="figcaption">SKLearn image with highlighted pixels</div>
</figure><p>As we can see the dataset relations are far more complex than our
previous examples. The histograms show that some numbers appear in those
pixel positions more than others, but the
<code>feature_vs_feature</code> plots are quite messy to try and
decipher. There are gaps and patches of colour suggesting that there is
some kind of structure there, but it’s far harder to inspect than the
penguin data. We can’t easily see definitive clusters in our 2D
representations, and we know our clustering algorithms will take a long
time to try and crunch 64 dimensions at once, so let’s see if we can
represent our 64D data in fewer dimensions.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section level1">
<h1 id="dimensionality-reduction-with-scikit-learn">Dimensionality reduction with Scikit-Learn<a class="anchor" aria-label="anchor" href="#dimensionality-reduction-with-scikit-learn"></a></h1>
<p>We will look at two commonly used techniques for dimensionality
reduction: Principal Component Analysis (PCA) and t-distributed
Stochastic Neighbor Embedding (t-SNE). Both of these techniques are
supported by Scikit-Learn.</p>
<div class="section level3">
<h3 id="principal-component-analysis-pca">Principal Component Analysis (PCA)<a class="anchor" aria-label="anchor" href="#principal-component-analysis-pca"></a></h3>
<p>PCA allows us to replace our 64 features with a smaller number of
dimensional representations that retain the majority of our
variance/relational data. Using Scikit-Learn lets apply PCA in a
relatively simple way.</p>
<p>For more in depth explanations of PCA please see the following links:
* <a href="https://builtin.com/data-science/step-step-explanation-principal-component-analysis" class="external-link">https://builtin.com/data-science/step-step-explanation-principal-component-analysis</a>
* <a href="https://scikit-learn.org/stable/modules/decomposition.html#pca" class="external-link">https://scikit-learn.org/stable/modules/decomposition.html#pca</a></p>
<p>Let’s apply PCA to the MNIST dataset and retain the two most-major
components:</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># PCA with 2 components</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> decomposition</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>x_pca <span class="op">=</span> pca.fit_transform(features)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="bu">print</span>(x_pca.shape)</span></code></pre>
</div>
<p>This returns us an array of 1797x2 where the 2 remaining columns(our
new “features” or “dimensions”) contain vector representations of the
first principle components (column 0) and second principle components
(column 1) for each of the images. We can plot these two new features
against each other:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># We are passing None becuase it is an unlabelled plot</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>plots_labels(x_pca, <span class="va">None</span>)</span></code></pre>
</div>
<figure><img src="../fig/results/pca_unlabelled.png" alt="Reduction using PCA" class="figure mx-auto d-block"><div class="figcaption">Reduction using PCA</div>
</figure><p>We now have a 2D representation of our 64D dataset that we can work
with instead. Let’s try some quick K-means clustering on our 2D
representation of the data. Because we already have some knowledge about
our data we can set <code>k=10</code> for the 10 digits present in the
dataset.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">import</span> sklearn.cluster <span class="im">as</span> skl_cluster</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>Kmean <span class="op">=</span> skl_cluster.KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>Kmean.fit(x_pca)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>clusters <span class="op">=</span> Kmean.predict(x_pca)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>plot_clusters(x_pca, clusters, Kmean)</span></code></pre>
</div>
<figure><img src="../fig/results/pca_clustered.png" alt="Reduction using PCA" class="figure mx-auto d-block"><div class="figcaption">Reduction using PCA</div>
</figure><p>And now we can compare how these clusters look against our actual
image labels by colour coding our first scatter plot:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>plot_clusters_labels(x_pca, labels)</span></code></pre>
</div>
<figure><img src="../fig/results/pca_labelled.png" alt="Reduction using PCA" class="figure mx-auto d-block"><div class="figcaption">Reduction using PCA</div>
</figure><p>PCA has done a valiant effort to reduce the dimensionality of our
problem from 64D to 2D while still retaining some of our key structural
information. We can see that the digits
<code>0</code>,<code>1</code>,<code>4</code>, and <code>6</code> cluster
up reasonably well even using a simple k-means test. However it does
look like there is still quite a bit of overlap between the remaining
digits, especially for the digits <code>5</code> and <code>8</code>. The
clustering is from perfect in the largest “blob”, but not a bad effort
from PCA given the substantial dimensionality reduction.</p>
<p>It’s worth noting that PCA does not handle outlier data well
primarily due to global preservation of structural information, and so
we will now look at a more complex form of learning that we can apply to
this problem.</p>
</div>
<div class="section level3">
<h3 id="t-distributed-stochastic-neighbor-embedding-t-sne">t-distributed Stochastic Neighbor Embedding (t-SNE)<a class="anchor" aria-label="anchor" href="#t-distributed-stochastic-neighbor-embedding-t-sne"></a></h3>
<p>t-SNE is a powerful example of manifold learning - a
non-deterministic non-linear approach to dimensionality reduction. A
<strong>manifold</strong> is a way to think about complex,
high-dimensional data as if it exists on a simpler, lower-dimensional
shape within that space. Imagine a crumpled piece of paper: while it
exists in 3D space when crumpled, the surface of the paper itself is
inherently 2D. Similarly, in many datasets, the meaningful patterns and
relationships lie along such “lower-dimensional surfaces” within the
high-dimensional space. For example, in image data like MNIST, the raw
pixels (hundreds of dimensions) may seem high-dimensional, but the
actual structure (the shapes of digits) is much simpler, often following
a lower-dimensional manifold. Manifold learning techniques like t-SNE
aim to “uncrumple” the data and flatten it into a lower-dimensional
space, while preserving the relationships between points as much as
possible.</p>
</div>
<div class="section level3">
<h3 id="intuition-for-t-sne">Intuition for t-SNE<a class="anchor" aria-label="anchor" href="#intuition-for-t-sne"></a></h3>
<p>t-SNE (<strong>t-distributed Stochastic Neighbor Embedding</strong>)
is a method for visualizing high-dimensional data by mapping it into a
low-dimensional space, typically 2D or 3D, while emphasizing <em>local
relationships</em>. It focuses on keeping nearby points close together,
helping to reveal clusters or patterns that may be hidden in the
original high-dimensional space.</p>
<p><strong>An analogy</strong>: Imagine moving a group of friends from a
large, crowded park into a much smaller garden while trying to keep
people who are chatting with each other close. You won’t care much about
preserving the exact distances between groups from the original
park—your main goal is to keep friends near each other in the smaller
space. Similarly, t-SNE prioritizes preserving these <em>local
connections</em>, while global distances between clusters may be
distorted or not reflect their true relationships. This distortion
happens because t-SNE sacrifices global structure to accurately capture
local neighborhoods. For example: - Two clusters that appear far apart
in the t-SNE plot may actually be closer in the original
high-dimensional space. - Similarly, clusters that appear close together
in the plot might not actually be neighbors in the original space.</p>
<p>As a result, while t-SNE is excellent for discovering <em>local
patterns</em> (e.g., clusters, subgroups), you should be cautious about
interpreting the relative distances between clusters. These are less
reliable and are influenced by how the algorithm optimizes its layout in
the reduced space. It’s best to use t-SNE as a tool to find grouping and
then validate these findings using additional analysis.</p>
<p>For more in depth explanations of t-SNE and manifold learning please
see the following links which also contain som very nice visual examples
of manifold learning in action: * <a href="https://thedatafrog.com/en/articles/visualizing-datasets/" class="external-link">https://thedatafrog.com/en/articles/visualizing-datasets/</a>
* <a href="https://scikit-learn.org/stable/modules/manifold.html" class="external-link">https://scikit-learn.org/stable/modules/manifold.html</a></p>
<p>Scikit-Learn allows us to apply t-SNE in a relatively simple way.
Lets code and apply t-SNE to the MNIST dataset in the same manner that
we did for the PCA example, and reduce the data down from 64D to 2D
again:</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># t-SNE embedding</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> manifold</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co"># initialising with "pca" explicitly preserves global structure</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>tsne <span class="op">=</span> manifold.TSNE(n_components<span class="op">=</span><span class="dv">2</span>, init<span class="op">=</span><span class="st">'pca'</span>, random_state <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>x_tsne <span class="op">=</span> tsne.fit_transform(features)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>plots_labels(x_tsne, <span class="va">None</span>)</span></code></pre>
</div>
<figure><img src="../fig/results/tsne_unlabelled.png" alt="Reduction using PCA" class="figure mx-auto d-block"><div class="figcaption">Reduction using PCA</div>
</figure><p>It looks like t-SNE has done a much better job of splitting our data
up into clusters using only a 2D representation of the data. Once again,
let’s run a simple k-means clustering on this new 2D representation, and
compare with the actual color-labelled data:</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>Kmean <span class="op">=</span> skl_cluster.KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>Kmean.fit(x_tsne)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>clusters <span class="op">=</span> Kmean.predict(x_tsne)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>plot_clusters(x_tsne, clusters, Kmean)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>plot_clusters_labels(x_tsne, labels)</span></code></pre>
</div>
<figure><img src="../fig/results/tsne_clustered.png" alt="Reduction using PCA" class="figure mx-auto d-block"><div class="figcaption">Reduction using PCA</div>
</figure><p>It looks like t-SNE has successfully separated out our digits into
accurate clusters using as little as a 2D representation and a simple
k-means clustering algorithm. It has worked so well that you can clearly
see several clusters which can be modelled, whereas for our PCA
representation we needed to rely heavily on the knowledge that we had 10
types of digits to cluster.</p>
<p>Additionally, if we had run k-means on all 64 dimensions this would
likely still be computing away, whereas we have already broken down our
dataset into accurate clusters, with only a handful of outliers and
potential misidentifications (remember, a good ML model isn’t a perfect
model!)</p>
<p>The major drawback of applying t-SNE to datasets is the large
computational requirement. Furthermore, hyper-parameter tuning of t-SNE
usually requires some trial and error to perfect.</p>
<p>Our example here is still a relatively simple example of 8x8 images
and not very typical of the modern problems that can now be solved in
the field of ML and DL. To account for even higher-order input data,
neural networks were developed to more accurately extract feature
information.</p>
<div id="exercise-working-in-three-dimensions" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="exercise-working-in-three-dimensions" class="callout-inner">
<h3 class="callout-title">Exercise: Working in three dimensions</h3>
<div class="callout-content">
<p>The above example has considered only two dimensions since humans can
visualize two dimensions very well. However, there can be cases where a
dataset requires more than two dimensions to be appropriately
decomposed. Modify the above programs to use three dimensions and create
appropriate plots. Do three dimensions allow one to better distinguish
between the digits?</p>
<div class="section level2">
<h2 id="solution-1">Solution<a class="anchor" aria-label="anchor" href="#solution-1"></a></h2>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>pca <span class="op">=</span> decomposition.PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>pca.fit(features)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>x_pca <span class="op">=</span> pca.transform(features)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(<span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>ax.scatter(x_pca[:, <span class="dv">0</span>], x_pca[:, <span class="dv">1</span>], x_pca[:, <span class="dv">2</span>], c<span class="op">=</span>labels,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>          cmap<span class="op">=</span>plt.cm.nipy_spectral, s<span class="op">=</span><span class="dv">9</span>, lw<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/results/pca_3d.svg" alt="Reduction to 3 components using pca" class="figure mx-auto d-block"><div class="figcaption">Reduction to 3 components using pca</div>
</figure><div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># t-SNE embedding</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>tsne <span class="op">=</span> manifold.TSNE(n_components<span class="op">=</span><span class="dv">3</span>, init<span class="op">=</span><span class="st">'pca'</span>,</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>        random_state <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>x_tsne <span class="op">=</span> tsne.fit_transform(features)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(<span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>ax.scatter(x_tsne[:, <span class="dv">0</span>], x_tsne[:, <span class="dv">1</span>], x_tsne[:, <span class="dv">2</span>], c<span class="op">=</span>labels,</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>          cmap<span class="op">=</span>plt.cm.nipy_spectral, s<span class="op">=</span><span class="dv">9</span>, lw<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="../fig/results/tsne_3d.svg" alt="Reduction to 3 components using tsne" class="figure mx-auto d-block"><div class="figcaption">Reduction to 3 components using tsne</div>
</figure></div>
</div>
</div>
</div>
<div id="exercise-parameters" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="exercise-parameters" class="callout-inner">
<h3 class="callout-title">Exercise: Parameters</h3>
<div class="callout-content">
<p>Look up parameters that can be changed in PCA and t-SNE, and
experiment with these. How do they change your resulting plots? Might
the choice of parameters lead you to make different conclusions about
your data?</p>
</div>
</div>
</div>
<div id="exercise-other-algorithms" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<span class="callout-header">Discussion</span>
<div id="exercise-other-algorithms" class="callout-inner">
<h3 class="callout-title">Exercise: Other algorithms</h3>
<div class="callout-content">
<p>There are other algorithms that can be used for doing dimensionality
reduction (for example the Higher Order Singular Value Decomposition
(HOSVD)). Do an internet search for some of these and examine the
example data that they are used on. Are there cases where they do
poorly? What level of care might you need to use before applying such
methods for automation in critical scenarios? What about for interactive
data exploration?</p>
</div>
</div>
</div>
<p>{% include links.md %}</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<span class="callout-header">Key Points</span>
<div class="callout-inner">
<div class="callout-content">
<ul><li>PCA is a linear dimensionality reduction technique for tabular
data</li>
<li>t-SNE is another dimensionality reduction technique for tabular data
that is more general than PCA</li>
</ul></div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>



      </div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="../instructor/05-clustering.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="../instructor/07-neural-networks.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="../instructor/05-clustering.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: Unsupervised methods
        </a>
        <a class="chapter-link float-end" href="../instructor/07-neural-networks.html" rel="next">
          Next: Neural Networks...
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/UW-Madison-DataScience/machine-learning-novice-sklearn-v2/edit/main/episodes/06-dimensionality-reduction.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/UW-Madison-DataScience/machine-learning-novice-sklearn-v2/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/UW-Madison-DataScience/machine-learning-novice-sklearn-v2/" class="external-link">Source</a></p>
				<p><a href="https://github.com/UW-Madison-DataScience/machine-learning-novice-sklearn-v2/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:endemann@wisc.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.17.1" class="external-link">sandpaper (0.17.1)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.7" class="external-link">varnish (1.0.7)</a></p>
			</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://UW-Madison-DataScience.github.io/machine-learning-novice-sklearn-v2/instructor/06-dimensionality-reduction.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "Unsupervised methods - Dimensionality reduction",
  "creativeWorkStatus": "active",
  "url": "https://UW-Madison-DataScience.github.io/machine-learning-novice-sklearn-v2/instructor/06-dimensionality-reduction.html",
  "identifier": "https://UW-Madison-DataScience.github.io/machine-learning-novice-sklearn-v2/instructor/06-dimensionality-reduction.html",
  "dateCreated": "2013-07-13",
  "dateModified": "2025-11-10",
  "datePublished": "2025-11-18"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

